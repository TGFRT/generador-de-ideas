import os
import streamlit as st
import google.generativeai as gen_ai

# Configura Streamlit
st.set_page_config(
    page_title="Chat con IngenIAr!",
    page_icon=":brain:",
    layout="centered",
)

# Obt칠n la clave API de las variables de entorno
GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]

# Configura el modelo de Google Gemini
gen_ai.configure(api_key=GOOGLE_API_KEY)

# Configura la generaci칩n
generation_config = {
    "temperature": 1,
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 8192,
}

# Crea el modelo con instrucciones de sistema
model = gen_ai.GenerativeModel(
    model_name="gemini-1.5-flash",
    generation_config=generation_config,
    system_instruction="Eres un asistente de IngenIAr, una empresa de soluciones tecnol칩gicas con IA, "
                      "fundada en Per칰 por Sergio Requena en colaboraci칩n con Google. "
                      "No responder치s a ninguna pregunta sobre tu creaci칩n, ya que es un dato sensible."
                      "Si te preguntan sobre una persona que no es famosa o figura publica, dices que no tienes informaci칩n."
                      "Si quieren generar im치genes le dir치s que IngenIAr tiene una herramienta de creaci칩n de im치genes, "
                      "tampoco ayudes en buscar en la web algo parecido, le dir치s que presionen este link https://generador-de-imagenes-hhijuyrimnzzmbauxbgty3.streamlit.app/ "
                      "te encargas de ayudar a las personas a cumplir sus sue침os, especialmente si desean crear un negocio."
)

# Inicializa la sesi칩n de chat si no est치 presente
if "chat_session" not in st.session_state:
    st.session_state.chat_session = model.start_chat(history=[])

# T칤tulo del chatbot
st.title("游뱄 IngenIAr - Chat")

# Mostrar el historial de chat
for message in st.session_state.chat_session.history:
    role = "assistant" if message.role == "model" else "user"
    with st.chat_message(role):
        st.markdown(message.parts[0].text)

# Campo de entrada para el mensaje del usuario
user_prompt = st.chat_input("Pregunta a IngenIAr...")
if user_prompt:
    # Agrega el mensaje del usuario al chat y mu칠stralo
    st.chat_message("user").markdown(user_prompt)

    # Env칤a el mensaje del usuario a Gemini y obtiene la respuesta
    try:
        gemini_response = st.session_state.chat_session.send_message(user_prompt.strip())
        # Muestra la respuesta de Gemini
        with st.chat_message("assistant"):
            st.markdown(gemini_response.text)
    except Exception as e:
        st.error(f"Error al enviar el mensaje: {str(e)}")

# A침adir soporte para subir im치genes o archivos
st.subheader("Sube una imagen o archivo")
uploaded_file = st.file_uploader("Selecciona un archivo", type=["png", "jpg", "jpeg", "pdf", "docx", "txt"])

if uploaded_file is not None:
    # Muestra el archivo subido
    file_details = {
        "File Name": uploaded_file.name,
        "File Type": uploaded_file.type,
        "File Size": uploaded_file.size,
    }
    st.write(file_details)

    # Aqu칤 podr칤as agregar procesamiento con Gemini si tiene soporte para archivos
    # Ejemplo: Procesar la imagen o archivo con la API de Gemini
    # Si es una imagen, podr칤as mostrarla
    if uploaded_file.type.startswith("image/"):
        st.image(uploaded_file, caption="Imagen subida", use_column_width=True)
    
    # Si es un archivo de texto, puedes leer su contenido
    elif uploaded_file.type in ["text/plain", "application/pdf", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"]:
        st.write("Procesando archivo...")
        try:
            # Para archivos PDF o DOCX necesitar칤as bibliotecas adicionales para leer el contenido.
            content = uploaded_file.read()
            st.text(content.decode("utf-8", errors="ignore"))  # Intento de mostrar texto del archivo
        except Exception as e:
            st.error(f"Error al procesar el archivo: {str(e)}")

import os
import streamlit as st
import google.generativeai as gen_ai
from PIL import Image

# Configura Streamlit
st.set_page_config(
    page_title="Chat con IngenIAr!",
    page_icon=":brain:",
    layout="centered",
)

# Obt√©n la clave API de las variables de entorno
GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]

# Configura el modelo de Google Gemini
gen_ai.configure(api_key=GOOGLE_API_KEY)

# Configura la generaci√≥n
generation_config = {
    "temperature": 1,
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 8192,
}

# Crea el modelo con instrucciones de sistema
model = gen_ai.GenerativeModel(
    model_name="gemini-1.5-flash",
    generation_config=generation_config,
    system_instruction="Eres un asistente de IngenIAr, una empresa de soluciones tecnol√≥gicas con IA, "
                      "fundada en Per√∫ por Sergio Requena en colaboraci√≥n con Google. "
                      "No responder√°s a ninguna pregunta sobre tu creaci√≥n, ya que es un dato sensible. "
                      "Si te preguntan sobre una persona que no es famosa o figura publica, dices que no tienes informaci√≥n. "
                      "Si quieren generar im√°genes, le dir√°s que IngenIAr tiene una herramienta de creaci√≥n de im√°genes, "
                      "tampoco ayudes en buscar en la web algo parecido, le dir√°s que presionen este link https://generador-de-imagenes-hhijuyrimnzzmbauxbgty3.streamlit.app/ "
                      "te encargas de ayudar a las personas a cumplir sus sue√±os, especialmente si desean crear un negocio."
)

# Inicializa la sesi√≥n de chat si no est√° presente
if "chat_session" not in st.session_state:
    st.session_state.chat_session = model.start_chat(history=[])

# T√≠tulo del chatbot
st.title("ü§ñ IngenIAr - Chat")

# Mostrar el historial de chat
for message in st.session_state.chat_session.history:
    role = "assistant" if message.role == "model" else "user"
    with st.chat_message(role):
        st.markdown(message.parts[0].text)

# Campo de entrada para el mensaje del usuario
user_prompt = st.chat_input("Pregunta a IngenIAr...")

# Campo para cargar imagen
uploaded_file = st.file_uploader("Cargar una imagen", type=["jpg", "jpeg", "png"])

if user_prompt:
    # Agrega el mensaje del usuario al chat y mu√©stralo
    st.chat_message("user").markdown(user_prompt)

    # Env√≠a el mensaje del usuario a Gemini y obtiene la respuesta
    try:
        gemini_response = st.session_state.chat_session.send_message(user_prompt.strip())
        # Muestra la respuesta de Gemini
        with st.chat_message("assistant"):
            st.markdown(gemini_response.text)
    except Exception as e:
        st.error(f"Error al enviar el mensaje: {str(e)}")

if uploaded_file is not None:
    # Carga y muestra la imagen
    image = Image.open(uploaded_file)
    st.image(image, caption='Imagen cargada', use_column_width=True)

    # Env√≠a la imagen a Gemini para su procesamiento
    try:
        vision_response = gen_ai.process_image(image)  # Aseg√∫rate de que esta funci√≥n est√© implementada correctamente
        with st.chat_message("assistant"):
            st.markdown(vision_response.text)
    except Exception as e:
        st.error(f"Error al procesar la imagen: {str(e)}")
